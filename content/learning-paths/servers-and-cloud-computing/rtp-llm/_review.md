---
review:
    - questions:
        question: >
            Can you run LLMs on Arm CPUs?
        answers:
            - "Yes"
            - "No"
        correct_answer: 1
        explanation: >
            Yes. The advancements made in the Generative AI space with smaller parameter models make LLM inference on CPUs very efficient.

    - questions:
        question: >
            Can rtp-llm be built and run on CPU?
        answers:
            - "Yes"
            - "No"
        correct_answer: 1
        explanation: >
            Yes. rtp-llm not only support built and run on GPU, but also it can be run on Arm CPU.

# ================================================================================
#       FIXED, DO NOT MODIFY
# ================================================================================
title: "Review"                 # Always the same title
weight: 20                      # Set to always be larger than the content in this path
layout: "learningpathall"       # All files under learning paths have this same wrapper
---
