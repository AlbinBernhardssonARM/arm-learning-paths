{{/*
    Demo page for the llm-chatbot, the first demo created in learn.arm.com.
    
    Where it is used:
        - learning paths, demo page
    
    Called from:
        - partials learning-paths/demo.html
    
    Calls to:
        - the demo's frontmater metadata (.Params)
    
    */}}
    
    
    
    <script>
    
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        let audio_cap_timeout; 
        let audio_cap_timeout_value = 3000;
        let isRecording = false;
    
        const audio_playback = document.getElementById('audio-playback');
        const audio_playback_substitute = document.getElementById('audio-playback-substitute');
        const audio_playback_controls_div = document.getElementById('audio-playback-controls-div');
        const audio_playback_missing = document.getElementById('no-waveform');
        const placeholder_for_audio_playback = document.getElementById('placeholder-for-audio-playback');
        const text_status = document.getElementById('status');
        const submit_btn = document.getElementById('send-to-server-btn');
        const icon_div = document.getElementById('audio-icon-div');
        const icon = document.getElementById('audio-action-icon');
        const icon_subtitle = document.getElementById('icon-subtitle');
        
    
        const status_msg__recording_timeout = "Auto-stopped. recording is capped at "+audio_cap_timeout_value/1000+"sec long."
        const status_msg__mic_permission_error = "Error accessing microphone. Please ensure you have granted permissions in your browser."
        const status_msg__transcription_show = "Transcription complete." // move 
    
    
    

        // Function to show the message
        function showStatus(text) {
            text_status.textContent = text; 
            text_status.classList.add('visible'); 
            text_status.classList.remove('hidden', 'removed'); 

            // Hide the message after 5 seconds
            setTimeout(() => {
                text_status.classList.add('hidden'); // Fade it out
                text_status.classList.remove('visible');
                // Remove it from the DOM flow after the fade-out transition (1s)
                setTimeout(() => {
                    text_status.classList.add('removed');
                }, 1000); // Match the duration of the fade-out transition
            }, 5000); // 5 seconds delay
        }

            
    
        icon_div.addEventListener('click', () => {
            if (!icon_div.classList.contains('disabled')) {
                if (!isRecording) {
                    startRecording();
                } else {
                    stopRecording();
                }
            }
        });
    
    
        async function startRecording() {
            try {
                // Start audio stream, asking permission for mic if not granted.
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.start();
                isRecording = true;
    
    
                // Cap recording at set time
                audio_cap_timeout = setTimeout(() => {
                    stopRecording();
                    showStatus(status_msg__recording_timeout);
                }, audio_cap_timeout_value); 
                
                // Indicate recording on UI
                if (icon.classList.contains('fa-microphone-lines')) {
                    // First recording of session
                    icon.classList.replace('fa-microphone-lines','fa-square-full');   
                }
                else {
                    // Re-recording
                    icon.classList.replace('fa-rotate-right','fa-square-full');
                    // hide audiPlaback, show placeholder
                    audio_playback_controls_div.style.display = 'none';
                    audio_playback_missing.style.display = 'flex';
                    audio_playback_substitute.classList.add('empty');
                    audio_playback_substitute.classList.remove('full');
                    placeholder_for_audio_playback.textContent = 'Re-recording audio.';
    
                }
                icon.classList.add('pulse');
                icon_subtitle.textContent = 'Stop';
    
    
                // Collect the audio data chunks
                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };
    
                // When the recording stops, create an audio file
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audio_playback_missing.style.display = 'none';
                    audio_playback_substitute.classList.add('full');
                    audio_playback_substitute.classList.remove('empty');
                    audio_playback.src = audioUrl;
                    audio_playback_controls_div.style.display = 'flex';
                    placeholder_for_audio_playback.textContent = 'Stored temporarily in browser local storage.'
                    submit_btn.disabled = 'false';
                    audioChunks = [];  // Reset the chunks for next recording
    
                    clearTimeout(audio_cap_timeout); // Reset timeout
                };
            } catch (error) {
                console.error('Error accessing microphone:', error);
                showStatus(status_msg__mic_permission_error);
            }
        }
    
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
    
                // Indicate stopped on UI
                icon.classList.replace('fa-square-full','fa-rotate-right');
                icon.classList.remove('pulse');
                icon_subtitle.textContent = 'Re-record';
                
                
            }
        }
    
    
        // Send audio to server on button click
        submit_btn.addEventListener('click', () => {
            sendAudioToServer(audioBlob);
        });
    
    
    
        function insertRandomSentenceWithDelay(div) {
            const sentences = [
                "The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.",
                "A journey of a thousand miles begins with a single step.\nThe quick brown fox jumps over the lazy dog.\nTo be or not to be, that is the question.\nTo be or not to be, that is the question. To be or not to be, that is the question.\n\nTo be or not to be, that is the question.",
            ];
            const randomIndex = Math.floor(Math.random() * sentences.length);
            const randomDelay = Math.floor(Math.random() * 4 + 1) * 1000; // Random delay between 1 and 4 seconds
            const sentence = sentences[randomIndex];
    
            setTimeout(() => {
                const transcription_loader = document.getElementById('transcription-loader');
                transcription_loader.style.display = 'none';
                // show transcription
                div.textContent = sentence;
    
                // remove disabled tag on rerun
                icon_div.classList.remove('disabled');
    
            }, randomDelay);
    
            // Return last message
            return sentence
    
        }
    
        // Function to send the audio to the spoof server
        function sendAudioToServer(audioBlob) {
            const transcription_div=document.getElementById('transcription-div');
            const transcription_p = document.getElementById('transcription-p');
            const transcription_loader = document.getElementById('transcription-loader');
    
            // Update UI components
            submit_btn.disabled = 'true';
            icon_div.classList.add('disabled');      
            transcription_div.style.display = 'block';
            transcription_loader.style.display = 'block';
            transcription_p.textContent = ''; // reset if there are some present
    
            // Send to server
            insertRandomSentenceWithDelay(transcription_p)
    
            /*
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');
            
            fetch('https://example.com/upload', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                console.log('Success:', data);
                status.textContent = 'Audio uploaded successfully.';
            })
            .catch((error) => {
                console.error('Error uploading audio:', error);
                status.textContent = 'Error uploading audio.';
            });
            */
        }
    
    </script>
    